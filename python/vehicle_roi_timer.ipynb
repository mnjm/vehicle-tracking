{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from yolov11_onnx_wrapper import YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnjm/.pyvenv/dl_default/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "\u001b[0;93m2025-02-09 09:43:10.038565 [W:onnxruntime:, coreml_execution_provider.cc:115 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 15 number of nodes in the graph: 320 number of nodes supported by CoreML: 304\u001b[m\n"
     ]
    }
   ],
   "source": [
    "model_path = Path(\"../yolo11s.onnx\")\n",
    "model = YOLOv11(\n",
    "    model_path=model_path,\n",
    "    valid_class_checker=lambda lbl_id, _: 1 <= lbl_id <= 8 # only detect vehicles\n",
    ")\n",
    "# vid_path_l = [ Path(\"../input_videos/5473765-uhd_3840_2160_24fps.mp4\") ]\n",
    "vid_path_l = Path(\"../input_videos\").glob(\"*.mp4\")\n",
    "out_vid_dir = Path(\"./out_vid_dir\")\n",
    "out_vid_dir.mkdir(exist_ok=True)\n",
    "\n",
    "test_b = True\n",
    "roi_color = (255, 0, 0)\n",
    "bbox_color = (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = 0\n",
    "total_colors = 30\n",
    "\n",
    "def generate_unique_colors():\n",
    "    global color_idx\n",
    "    hue = int((color_idx * 180 / total_colors) % 180)\n",
    "    color_idx += 1\n",
    "    saturation, value = 200, 255\n",
    "    color = np.uint8([[[hue, saturation, value]]])\n",
    "    bgr_color = cv2.cvtColor(color, cv2.COLOR_HSV2BGR)[0][0]\n",
    "    return tuple(map(int, bgr_color))\n",
    "\n",
    "def format_time(secs):\n",
    "    mins, secs = secs / 60, secs % 60\n",
    "    ret_str = f\"{secs:.2f}\"\n",
    "    if mins > 0:\n",
    "        ret_str = f\"{int(mins)} {ret_str}\"\n",
    "    return ret_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video WxH:3840x2160 FPS:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 09:43:13.055 Python[4243:49529] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-09 09:43:13.055 Python[4243:49529] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video WxH:3840x2160 FPS:15\n",
      "Video WxH:3840x2160 FPS:30\n",
      "Video WxH:1280x720 FPS:50\n",
      "Video WxH:3840x2160 FPS:23\n"
     ]
    }
   ],
   "source": [
    "exit_b = False\n",
    "for vid_path in vid_path_l:\n",
    "    \n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Reading {vid_path.name} video failed.\")\n",
    "        continue\n",
    "    \n",
    "    vid_w, vid_h, fps = map(lambda x: int(cap.get(x)), (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    print(f\"Video WxH:{vid_w}x{vid_h} FPS:{fps}\")\n",
    "    \n",
    "    # Read ROI\n",
    "    roi_path = str(vid_path.parent / vid_path.stem) + \"_roi.txt\"\n",
    "    roi = np.loadtxt(roi_path, dtype=np.int32)\n",
    "    assert roi.shape == (4,), f\"Invalid ROI {roi}\"\n",
    "    \n",
    "    out_vid_path = out_vid_dir / vid_path.name\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out_vid = cv2.VideoWriter(out_vid_path, fourcc, fps, (vid_w, vid_h))\n",
    "\n",
    "    det_l = []\n",
    "    dist_thresh = 40\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break \n",
    "        \n",
    "        x1, y1, x2, y2 = roi\n",
    "        img = frame[y1:y2, x1:x2, :]\n",
    "        bbox_l = model.detect(img)\n",
    "        cv2.rectangle(frame, roi[:2], roi[2:], roi_color, 2)\n",
    "        new_det_l = []\n",
    "        for bbox_idx, bbox in enumerate(bbox_l):\n",
    "            center = np.array([(bbox.x1 + bbox.x2) / 2, (bbox.y1 + bbox.y2) / 2])\n",
    "            # calc dist from all known objects\n",
    "            min_idx, min_dist = -1, np.inf\n",
    "            for idx, det in enumerate(det_l):\n",
    "                d_center = det['center']\n",
    "                dist = np.linalg.norm(center - d_center)\n",
    "                if dist < min_dist:\n",
    "                    min_idx, min_dist = idx, dist\n",
    "            if min_dist < dist_thresh:\n",
    "                color = det_l[min_idx]['color']\n",
    "                frame_count = det_l[min_idx]['frame_count'] + 1\n",
    "            else:\n",
    "                color = generate_unique_colors()\n",
    "                frame_count = 1\n",
    "            new_det_l.append({\n",
    "                'color': color,\n",
    "                'frame_count': frame_count,\n",
    "                'center': center,\n",
    "                'bbox_idx': bbox_idx,\n",
    "            })\n",
    "        \n",
    "        det_l = new_det_l\n",
    "        for det in det_l:\n",
    "            bbox = bbox_l[det['bbox_idx']]\n",
    "            color = det['color']\n",
    "            disp_bbox = np.array([bbox.x1, bbox.y1, bbox.x2, bbox.y2], dtype=np.int32).reshape(2, 2) + roi[:2]\n",
    "            x1, y1, x2, y2 = disp_bbox.reshape(-1)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            # time \n",
    "            t = det['frame_count'] / fps\n",
    "            mins, secs = int(t // 60), t % 60\n",
    "            t_str = f\"{mins}:{secs:.2f}\"\n",
    "            bbox_center = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            bbox_height = y2 - y1\n",
    "            font_scale = max(0.5, bbox_height / 200)\n",
    "            font_thickness = max(1, int(font_scale * 2))\n",
    "            txt_size, _ = cv2.getTextSize(t_str, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
    "            txt_pos = int(bbox_center[0] - txt_size[0] * .5), int(bbox_center[1] - txt_size[1] * .5)\n",
    "            cv2.putText(frame, t_str, txt_pos, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness, cv2.LINE_AA)\n",
    "            \n",
    "        out_vid.write(frame)\n",
    "        cv2.imshow('show', frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('n'):\n",
    "            break\n",
    "        if key == ord('q'):\n",
    "            exit_b = True\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    out_vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    if exit_b:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
